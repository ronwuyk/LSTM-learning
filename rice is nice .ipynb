{
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3399185,
          "sourceType": "datasetVersion",
          "datasetId": 2049052
        }
      ],
      "dockerImageVersionId": 30732,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronwuyk/LSTM-learning/blob/master/rice%20is%20nice%20.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import sys\n",
        "import pandas as pd\n",
        "import keras\n",
        "import seaborn as sns\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential"
      ],
      "metadata": {
        "id": "ZNCGNrlYn3HQ",
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:14.801147Z",
          "iopub.execute_input": "2024-07-01T03:50:14.801496Z",
          "iopub.status.idle": "2024-07-01T03:50:26.588409Z",
          "shell.execute_reply.started": "2024-07-01T03:50:14.801467Z",
          "shell.execute_reply": "2024-07-01T03:50:26.587648Z"
        },
        "trusted": true
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:26.589817Z",
          "iopub.execute_input": "2024-07-01T03:50:26.590329Z",
          "iopub.status.idle": "2024-07-01T03:50:27.008611Z",
          "shell.execute_reply.started": "2024-07-01T03:50:26.590302Z",
          "shell.execute_reply": "2024-07-01T03:50:27.007499Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NqyTgZDMJM_",
        "outputId": "949b9ad4-5f94-4acf-8f5b-49eab2a248be"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 9319562924630156142\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14626652160\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 11688840955243427660\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "#print(f\"Keras Version: {keras.__version__}\")\n",
        "print()\n",
        "print(f\"Python Version: {sys.version}\")\n",
        "print(f\"Pandas Version: {pd.__version__}\")\n",
        "print(f\"Numpy Version: {np.__version__}\")\n",
        "print(f\"Seaborn Version: {sns.__version__}\")\n",
        "gpu = len(tf.config.list_physical_devices('GPU')) > 0\n",
        "print()\n",
        "print(\"GPU is\", \"PRESENT\" if gpu else \"NOT AVAILABLE\")\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:27.010213Z",
          "iopub.execute_input": "2024-07-01T03:50:27.010525Z",
          "iopub.status.idle": "2024-07-01T03:50:27.026827Z",
          "shell.execute_reply.started": "2024-07-01T03:50:27.010499Z",
          "shell.execute_reply": "2024-07-01T03:50:27.025854Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNNNSR2QMJNA",
        "outputId": "ebe28be0-078b-4f4e-f2cb-a744895bb59a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.15.0\n",
            "\n",
            "Python Version: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Pandas Version: 2.0.3\n",
            "Numpy Version: 1.25.2\n",
            "Seaborn Version: 0.13.1\n",
            "\n",
            "GPU is PRESENT\n",
            "Num GPUs Available:  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:27.029088Z",
          "iopub.execute_input": "2024-07-01T03:50:27.029880Z",
          "iopub.status.idle": "2024-07-01T03:50:28.086665Z",
          "shell.execute_reply.started": "2024-07-01T03:50:27.029853Z",
          "shell.execute_reply": "2024-07-01T03:50:28.085478Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MbPN7QXMJNB",
        "outputId": "8c650265-9147-43cf-a0dc-243972efec3d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jul  2 02:05:51 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P0              31W /  70W |    103MiB / 15360MiB |      3%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -a"
      ],
      "metadata": {
        "id": "QxTgbBnVyZoW",
        "outputId": "ff5c0bc8-8b99-4367-fd6f-3bfe0f22a384",
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:28.088122Z",
          "iopub.execute_input": "2024-07-01T03:50:28.088427Z",
          "iopub.status.idle": "2024-07-01T03:50:29.037710Z",
          "shell.execute_reply.started": "2024-07-01T03:50:28.088399Z",
          "shell.execute_reply": "2024-07-01T03:50:29.036782Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linux 6686102731bf 6.1.85+ #1 SMP PREEMPT_DYNAMIC Tue Jun 18 14:18:04 UTC 2024 x86_64 x86_64 x86_64 GNU/Linux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adapting a CNN for Rice Variety Classification\n",
        "\n",
        "This guide will walk you through adapting the Convolutional Neural Network (CNN) architecture from TensorFlow's image classification tutorial ([https://www.tensorflow.org/tutorials/images/classification](https://www.tensorflow.org/tutorials/images/classification)) to a new dataset containing images of five different rice varieties. You'll build and train the model to achieve at least 88% accuracy on the testing/validation set.\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "* Familiarity with TensorFlow and Keras for building deep learning models.\n",
        "* Basic understanding of Convolutional Neural Networks (CNNs).\n",
        "* Loaded rice variety image dataset with training, validation, and testing splits.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Import Libraries and Load Data:**\n",
        "\n",
        "   - Start by importing the necessary libraries like TensorFlow, NumPy, and Matplotlib.\n",
        "   - Load your pre-existing rice variety image dataset using TensorFlow's data loading functionalities (e.g., `tf.keras.preprocessing.image.ImageDataGenerator`). Remember to split the data into training, validation, and testing sets.\n",
        "\n",
        "2. **Define the CNN Architecture:**\n",
        "\n",
        "   - The provided TensorFlow tutorial uses a basic CNN architecture with convolutional and pooling layers followed by dense layers.\n",
        "   - Modify this architecture to suit your specific dataset. Here are some considerations:\n",
        "     - Experiment with the number and configuration of convolutional layers (filter size, number of filters, activation functions).\n",
        "     - Consider adding techniques like batch normalization and dropout layers to improve model regularization.\n",
        "     - Adjust the number of units in the dense layers based on the complexity of your data.\n",
        "\n",
        "3. **Compile the Model:**\n",
        "\n",
        "   - Once you've defined your CNN architecture, compile the model using a suitable optimizer (e.g., Adam), loss function (e.g., categorical cross-entropy for multi-class classification), and metrics (e.g., accuracy).\n",
        "\n",
        "4. **Implement Training Loop with Early Stopping:**\n",
        "\n",
        "   - Define a training loop that iterates through the training data in batches.\n",
        "   - Inside the loop:\n",
        "     - Feed the training data to the model for training.\n",
        "     - Track training metrics (loss and accuracy) on each batch.\n",
        "     - Evaluate the model's performance on the validation set periodically (e.g., after each epoch).\n",
        "   - Implement an Early Stopping callback to halt training if the validation accuracy doesn't improve for a predefined number of epochs. This helps prevent overfitting.\n",
        "\n",
        "5. **Train the Model:**\n",
        "\n",
        "   - Train the model using the defined training loop. Monitor the training progress and validation accuracy.\n",
        "   - If the validation accuracy plateaus or starts decreasing, adjust hyperparameters (learning rate, number of epochs) or modify the model architecture and retrain.\n",
        "\n",
        "6. **Evaluate the Model:**\n",
        "\n",
        "   - After training, evaluate the final model performance on the unseen testing set.\n",
        "   - Ensure the testing accuracy meets or exceeds the target of 88%.\n",
        "\n",
        "**Additional Tips:**\n",
        "\n",
        "* Visualize the training and validation accuracy/loss curves to identify potential overfitting or underfitting issues.\n",
        "* Consider data augmentation techniques to increase the size and diversity of your training data.\n",
        "* Experiment with different learning rate schedules to optimize training speed and convergence.\n",
        "\n",
        "By following these steps and iteratively refining your model architecture and training process, you should be able to achieve a CNN model with at least 88% accuracy for your rice variety classification task. Remember to adapt and modify these instructions based on your specific dataset and hardware limitations.\n"
      ],
      "metadata": {
        "id": "AI_WlQosMJNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data downloading\n",
        "import pathlib\n",
        "\n",
        "dataset_url = \"/kaggle/input/Rice_Image_Dataset\"\n",
        "#data_dir = tf.keras.utils.get_file('rice_photos.tar', origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(dataset_url).with_suffix('')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:29.039007Z",
          "iopub.execute_input": "2024-07-01T03:50:29.039283Z",
          "iopub.status.idle": "2024-07-01T03:50:29.044223Z",
          "shell.execute_reply.started": "2024-07-01T03:50:29.039257Z",
          "shell.execute_reply": "2024-07-01T03:50:29.043269Z"
        },
        "trusted": true,
        "id": "DhhiHNz-MJNE"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print(image_count)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:29.045562Z",
          "iopub.execute_input": "2024-07-01T03:50:29.045825Z",
          "iopub.status.idle": "2024-07-01T03:50:33.811210Z",
          "shell.execute_reply.started": "2024-07-01T03:50:29.045803Z",
          "shell.execute_reply": "2024-07-01T03:50:33.810262Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWWoFhCpMJNF",
        "outputId": "652f2e3a-32a8-4871-e52a-4f17af23aa42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:33.812418Z",
          "iopub.execute_input": "2024-07-01T03:50:33.812826Z",
          "iopub.status.idle": "2024-07-01T03:50:33.817372Z",
          "shell.execute_reply.started": "2024-07-01T03:50:33.812792Z",
          "shell.execute_reply": "2024-07-01T03:50:33.816534Z"
        },
        "trusted": true,
        "id": "mKH21pTcMJNF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:50:33.818532Z",
          "iopub.execute_input": "2024-07-01T03:50:33.818789Z",
          "iopub.status.idle": "2024-07-01T03:51:15.327873Z",
          "shell.execute_reply.started": "2024-07-01T03:50:33.818766Z",
          "shell.execute_reply": "2024-07-01T03:51:15.326853Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "qiIexIysMJNG",
        "outputId": "26f3ad31-9f17-46d0-e9ff-9542a123bd9e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Could not find directory /kaggle/input/Rice_Image_Dataset",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-6deeeec64186>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_ds = tf.keras.utils.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m     image_paths, labels, class_names = dataset_utils.index_directory(\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mlist_directory_v2\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    766\u001b[0m   \"\"\"\n\u001b[1;32m    767\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m     raise errors.NotFoundError(\n\u001b[0m\u001b[1;32m    769\u001b[0m         \u001b[0mnode_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Could not find directory /kaggle/input/Rice_Image_Dataset"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:51:15.331157Z",
          "iopub.execute_input": "2024-07-01T03:51:15.331507Z",
          "iopub.status.idle": "2024-07-01T03:51:31.104960Z",
          "shell.execute_reply.started": "2024-07-01T03:51:15.331479Z",
          "shell.execute_reply": "2024-07-01T03:51:31.104194Z"
        },
        "trusted": true,
        "id": "NRkDGRCjMJNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T04:11:49.532063Z",
          "iopub.execute_input": "2024-07-01T04:11:49.532480Z",
          "iopub.status.idle": "2024-07-01T04:11:49.537489Z",
          "shell.execute_reply.started": "2024-07-01T04:11:49.532449Z",
          "shell.execute_reply": "2024-07-01T04:11:49.536565Z"
        },
        "trusted": true,
        "id": "UcgFnoPgMJNG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\",\n",
        "                      input_shape=(img_height,\n",
        "                                  img_width,\n",
        "                                  3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:51:31.105969Z",
          "iopub.execute_input": "2024-07-01T03:51:31.106231Z",
          "iopub.status.idle": "2024-07-01T03:51:31.133536Z",
          "shell.execute_reply.started": "2024-07-01T03:51:31.106208Z",
          "shell.execute_reply": "2024-07-01T03:51:31.132747Z"
        },
        "trusted": true,
        "id": "2iKFAvYNMJNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Dropout(0.2),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "#  layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:52:06.271081Z",
          "iopub.execute_input": "2024-07-01T03:52:06.271454Z",
          "iopub.status.idle": "2024-07-01T03:52:06.289518Z",
          "shell.execute_reply.started": "2024-07-01T03:52:06.271423Z",
          "shell.execute_reply": "2024-07-01T03:52:06.288605Z"
        },
        "trusted": true,
        "id": "N40WUJTrMJNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:52:13.127288Z",
          "iopub.execute_input": "2024-07-01T03:52:13.127646Z",
          "iopub.status.idle": "2024-07-01T03:52:13.146664Z",
          "shell.execute_reply.started": "2024-07-01T03:52:13.127608Z",
          "shell.execute_reply": "2024-07-01T03:52:13.145950Z"
        },
        "trusted": true,
        "id": "J6UKHXEBMJNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:52:18.565297Z",
          "iopub.execute_input": "2024-07-01T03:52:18.566163Z",
          "iopub.status.idle": "2024-07-01T03:52:18.591824Z",
          "shell.execute_reply.started": "2024-07-01T03:52:18.566127Z",
          "shell.execute_reply": "2024-07-01T03:52:18.590958Z"
        },
        "trusted": true,
        "id": "dBI85Mz8MJNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training model\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=epochs\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T03:52:40.179431Z",
          "iopub.execute_input": "2024-07-01T03:52:40.179786Z",
          "iopub.status.idle": "2024-07-01T04:01:51.558401Z",
          "shell.execute_reply.started": "2024-07-01T03:52:40.179758Z",
          "shell.execute_reply": "2024-07-01T04:01:51.557456Z"
        },
        "trusted": true,
        "id": "l9de9cNtMJNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T04:02:01.403099Z",
          "iopub.execute_input": "2024-07-01T04:02:01.403936Z",
          "iopub.status.idle": "2024-07-01T04:02:01.431672Z",
          "shell.execute_reply.started": "2024-07-01T04:02:01.403891Z",
          "shell.execute_reply": "2024-07-01T04:02:01.430839Z"
        },
        "trusted": true,
        "id": "uj_ZI9PnMJNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot chart the accuracy and loss of the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T04:02:07.494865Z",
          "iopub.execute_input": "2024-07-01T04:02:07.496193Z",
          "iopub.status.idle": "2024-07-01T04:02:07.996162Z",
          "shell.execute_reply.started": "2024-07-01T04:02:07.496149Z",
          "shell.execute_reply": "2024-07-01T04:02:07.995272Z"
        },
        "trusted": true,
        "id": "-kJDuWWiMJNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict new input\n",
        "\n",
        "rice_url = \"https://c8.alamy.com/comp/CXFFDA/organic-white-rice-sample-CXFFDA.jpg\"\n",
        "rice_path = tf.keras.utils.get_file('White_rice', rice_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    rice_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-07-01T04:12:02.304708Z",
          "iopub.execute_input": "2024-07-01T04:12:02.305386Z",
          "iopub.status.idle": "2024-07-01T04:12:02.500717Z",
          "shell.execute_reply.started": "2024-07-01T04:12:02.305352Z",
          "shell.execute_reply": "2024-07-01T04:12:02.499961Z"
        },
        "trusted": true,
        "id": "7vKBYi3JMJNJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dchH-xIfMJNJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}